{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import math \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "# from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_per_columns(value_counts: pd.core.series.Series, nbr_of_rank=6): # video=6 AND article 3\n",
    "    ranks = list(range(1, (nbr_of_rank + 1)))\n",
    "    cols_values_tuple = [c for c in value_counts.items()]\n",
    "    ranks_found = [v[0] for v in cols_values_tuple]\n",
    "    ranks_not_found = [rank for rank in ranks if rank not in ranks_found]\n",
    "    values_tuple_second = [(v, 0) for v in ranks_not_found]\n",
    "    values_tuple_complete = cols_values_tuple + values_tuple_second\n",
    "\n",
    "    values_tuple_complete = sorted(values_tuple_complete, key=lambda x: x[0])\n",
    "    counts = [v[1] for v in values_tuple_complete]\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for Chi-Square Goodness of Fit Test\n",
    "def prepare_data(df: pd.DataFrame, nbr_of_rank=6):\n",
    "    # remove user column\n",
    "    if \"user\" in df.columns.values.tolist():\n",
    "        df = df.drop(columns=['user'])\n",
    "    \n",
    "    # nbr_of_rank = 6\n",
    "    factors_row = {}\n",
    "    new_rows = []\n",
    "    columns_refs = []\n",
    "    for name in df.columns.values:\n",
    "        r = get_counts_per_columns(df[name].value_counts(), nbr_of_rank=nbr_of_rank)\n",
    "        factors_row[name] = r\n",
    "        new_rows.append(r)\n",
    "        columns_refs.append(name)\n",
    "\n",
    "    columns_names = [f\"rank {i}\" for i in list(range(1, (nbr_of_rank + 1)))]\n",
    "    df = pd.DataFrame(new_rows, columns=columns_names)\n",
    "    df.insert(0, 'factors', columns_refs)\n",
    "\n",
    "    return (df, columns_refs, new_rows, factors_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def get_chi_test_result(observed_info: list):\n",
    "    # observed_info = [[100, 200, 300], [50, 60, 70]]\n",
    "\n",
    "    # Print the observed frequencies\n",
    "    # print(\"Observed frequencies:\")\n",
    "    # for row in observed_info:\n",
    "    #     print(row)\n",
    "\n",
    "    # Perform the chi-square test\n",
    "    # stat, p, dof = chi2_contingency(observed_info)\n",
    "    chi2, p, dof, expected = chi2_contingency(observed_info)\n",
    "\n",
    "    # Set the significance level (alpha)\n",
    "    significance_level = 0.05\n",
    "\n",
    "    # Print the degree of freedom and p-value\n",
    "    print(\"p-value:\", p)\n",
    "    print(\"\\nDegree of freedom:\", dof)\n",
    "    print(\"chi2-value:\", chi2)\n",
    "\n",
    "    # Interpret the results\n",
    "    if False:\n",
    "        if p <= significance_level:\n",
    "            print(\"Reject NULL HYPOTHESIS: There is a significant association between the variables OR factors.\")\n",
    "            # print(\"Reject the null hypothesis: There is a significant association between the variables.\")\n",
    "        else:\n",
    "            print(\"ACCEPT NULL HYPOTHESIS: No significant association between the variables OR factors.\")\n",
    "            # print(\"Fail to reject the null hypothesis: There is no significant association between the variables.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sample of n (default 100) User Opinion Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def save_csv(df: pd.DataFrame, filename: str = \"sample_data.csv\"):\n",
    "    df.to_csv(filename, encoding='utf-8', index=False)\n",
    "\n",
    "def generate_rows_data(columns_names: list, nbr_of_rank=6, nbr_of_sample = 100, csv_file = True):\n",
    "    data = []\n",
    "    for i in list(range(nbr_of_sample)):\n",
    "        row = random.sample(range(1, (nbr_of_rank + 1)), nbr_of_rank) # random.sample(range(1, 7), 6)\n",
    "        row = [f\"Rank {i}\" for i in row]\n",
    "        data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=columns_names)\n",
    "    df.insert(0, 'user', range(1, len(df) + 1))\n",
    "\n",
    "    if csv_file:\n",
    "        save_csv(df=df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Factor Weight for Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Creation date</th>\n",
       "      <th>No. of Views</th>\n",
       "      <th>No. of Likes on YouTube</th>\n",
       "      <th>Rating on CourseMapper</th>\n",
       "      <th>No of. Save on CourseMapper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Similarity Score  Creation date  No. of Views  No. of Likes on YouTube  \\\n",
       "95                 6              5             2                        4   \n",
       "96                 5              4             2                        3   \n",
       "97                 5              2             3                        4   \n",
       "98                 5              2             3                        1   \n",
       "99                 5              2             1                        4   \n",
       "\n",
       "    Rating on CourseMapper  No of. Save on CourseMapper  \n",
       "95                       3                            1  \n",
       "96                       6                            1  \n",
       "97                       1                            6  \n",
       "98                       6                            4  \n",
       "99                       3                            6  "
      ]
     },
     "execution_count": 2162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_read_1 = ['Similarity Score', 'Creation date', 'No. of Views', \n",
    "                   \"No. of Likes on YouTube\", \"Rating on CourseMapper\",\n",
    "                   \"No of. Save on CourseMapper\"\n",
    "                ]\n",
    "columns_to_read_2 = ['Similarity Score', \"Rating on CourseMapper\",\n",
    "                   \"No of. Save on CourseMapper\"\n",
    "                ]\n",
    "\n",
    "nbr_of_rank = 6\n",
    "# df = pd.read_excel(\"factors ranking 2 (Responses).xlsx\", usecols=columns_to_read_1)\n",
    "# df = pd.read_excel(\"factors ranking 2 (Responses)_3_f.xlsx\", usecols=columns_to_read_2)\n",
    "# df = generate_rows_data(columns_names=columns_to_read_1, nbr_of_rank=6, nbr_of_sample=100)\n",
    "# df = generate_rows_data(columns_names=columns_to_read_2, nbr_of_rank=nbr_of_rank, nbr_of_sample=10)\n",
    "\n",
    "ROOT = \"/Users/wkana001/Desktop/work/tests/sch\"\n",
    "# df = pd.read_csv(f\"{ROOT}/sample_data.csv\", usecols=columns_to_read_1)\n",
    "df = pd.read_csv(\"sample_data.csv\", usecols=columns_to_read_1)\n",
    "\n",
    "def rename_label_rank(x):\n",
    "    if x == \"Rank 1\":\n",
    "        return 1\n",
    "    elif x == \"Rank 2\":\n",
    "        return 2\n",
    "    elif x == \"Rank 3\":\n",
    "        return 3\n",
    "    elif x == \"Rank 4\":\n",
    "        return 4\n",
    "    elif x == \"Rank 5\":\n",
    "        return 5\n",
    "    elif x == \"Rank 6\":\n",
    "        return 6\n",
    "    return x\n",
    "\n",
    "def reverse_rank_to_weight(x):\n",
    "    if x == 1:\n",
    "        return 6\n",
    "    elif x == 2:\n",
    "        return 5\n",
    "    elif x == 3:\n",
    "        return 4\n",
    "    elif x == 4:\n",
    "        return 3\n",
    "    elif x == 5:\n",
    "        return 2\n",
    "    elif x == 6:\n",
    "        return 1\n",
    "    return x\n",
    "\n",
    "for name in df.columns.values:\n",
    "   df[name] = df[name].apply(lambda x: rename_label_rank(x))\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # chisqt = pd.crosstab(BIKE.holiday, BIKE.weathersit, margins=True)\n",
    "# # cross_tab = pd.crosstab(df['Similarity Score'], df['Creation date'], df['No. of Views']\n",
    "# #                         # df['No. of Likes on YouTube'], df['Rating on CourseMapper'], \n",
    "# #                         # df['No of. Save on CourseMapper']\n",
    "# #                         )\n",
    "# # cross_tab = pd.crosstab(df['Similarity Score'], [df['Creation date'], df['No. of Views'], \n",
    "# #                                        df['No. of Likes on YouTube'], df['Rating on CourseMapper'], \n",
    "# #                                        df['No of. Save on CourseMapper']\n",
    "# #                                        ]\n",
    "# #                         )\n",
    "# # cross_tab\n",
    "\n",
    "# # data = df.head(5).to_dict(orient='list')\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Given dictionary with 'list' orientation\n",
    "# data = {\n",
    "#     'A': [2, 2, 2, 2, 2],\n",
    "#     'B': [5, 4, 6, 5, 4],\n",
    "#     'C': [4, 1, 1, 6, 3],\n",
    "#     'D': [3, 6, 5, 3, 5],\n",
    "#     'E': [1, 5, 4, 4, 1],\n",
    "#     'F': [6, 3, 3, 1, 6]\n",
    "# }\n",
    "\n",
    "# # Convert dictionary to DataFraåme\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Perform cross-tabulation\n",
    "# # cross_tab = pd.crosstab(df['A'], [df['B'], df['C'], df['D'], df['E'], df['F']])\n",
    "# cross_tab = pd.crosstab(df['B'], df['C'])\n",
    "\n",
    "# # Display the cross-tabulation\n",
    "# print(\"Cross-tabulation:\")\n",
    "# cross_tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.05526178616911542\n",
      "\n",
      "Degree of freedom: 25\n",
      "chi2-value: 37.199999999999996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>rank 1</th>\n",
       "      <th>rank 2</th>\n",
       "      <th>rank 3</th>\n",
       "      <th>rank 4</th>\n",
       "      <th>rank 5</th>\n",
       "      <th>rank 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Similarity Score</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creation date</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No. of Views</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No. of Likes on YouTube</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rating on CourseMapper</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No of. Save on CourseMapper</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       factors  rank 1  rank 2  rank 3  rank 4  rank 5  rank 6\n",
       "0             Similarity Score      12      19      15      17      22      15\n",
       "1                Creation date      15      11      18      28      17      11\n",
       "2                 No. of Views      16      14      20      14      12      24\n",
       "3      No. of Likes on YouTube      25      16      13      12      17      17\n",
       "4       Rating on CourseMapper      14      25      15      17      17      12\n",
       "5  No of. Save on CourseMapper      18      15      19      12      15      21"
      ]
     },
     "execution_count": 2165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppd = prepare_data(df=df, nbr_of_rank=nbr_of_rank)\n",
    "get_chi_test_result(observed_info=ppd[2])\n",
    "\n",
    "ppd[0].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Similarity Score': 22,\n",
       " 'Creation date': 28,\n",
       " 'No. of Views': 24,\n",
       " 'No. of Likes on YouTube': 25,\n",
       " 'Rating on CourseMapper': 25,\n",
       " 'No of. Save on CourseMapper': 21}"
      ]
     },
     "execution_count": 2166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_highest_counts = {}\n",
    "for k,v in ppd[3].items():\n",
    "    factor_highest_counts[k] = max(v)\n",
    "\n",
    "factor_weights = factor_highest_counts\n",
    "factor_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factor_weights(df: pd.DataFrame):\n",
    "    # remove user column\n",
    "    if \"user\" in df.columns.values.tolist():\n",
    "        df = df.drop(columns=['user'])\n",
    "        \n",
    "    factors_weights_cols = {}\n",
    "    for name in df.columns.values:\n",
    "        df[name] = df[name].apply(lambda x: reverse_rank_to_weight(x))\n",
    "        col_values = df[name].tolist()\n",
    "        factors_weights_cols[name] = round((sum(col_values) / len(col_values)), 3)\n",
    "\n",
    "    return factors_weights_cols\n",
    "\n",
    "# factor_weights = get_factor_weights(df)\n",
    "# factor_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize as normalize_sklearn, MinMaxScaler as MinMaxScaler_sklearn\n",
    "\n",
    "def normalize_factor_weights(factor_weights: dict, method_type = \"l1\", complete=True, sum_value=True): # List[float]\n",
    "    \"\"\"\n",
    "    https://www.pythonprog.com/sklearn-preprocessing-normalize/#Normalization_Techniques\n",
    "    TypeScript: https://sklearn.vercel.app/guide/install\n",
    "\n",
    "    factor_weights = { 'similarity_score': 0.7, 'creation_date': 0.3, 'nbr_views': 0.3, \n",
    "            'nbr_likes_youTube': 0.1, 'rating_courseMapper': 0.1, 'nbr_save_courseMapper': 0.1\n",
    "        }\n",
    "\n",
    "    method_type: normalization techniques\n",
    "        l1: L1 normalization, also known as L1 norm normalization or Manhattan normalization\n",
    "        l1: L2 normalization, also known as L2 norm normalization or Euclidean normalization\n",
    "        max: Max Normalization\n",
    "        min-max: Min-Max\n",
    "    \"\"\"\n",
    "    normalized_weights = None\n",
    "    scaled_data = None\n",
    "    \n",
    "    weights = [value for key, value in factor_weights.items()]\n",
    "    factor_names = [key for key, value in factor_weights.items()]\n",
    "\n",
    "    if method_type == \"l1\":\n",
    "        normalized_weights = normalize_sklearn([weights], norm=method_type).tolist()\n",
    "    if method_type == \"l2\":\n",
    "        normalized_weights = normalize_sklearn([weights], norm=method_type).tolist()\n",
    "    if method_type == \"max\":\n",
    "        normalized_weights = normalize_sklearn([weights], norm=method_type).tolist()\n",
    "    if method_type == \"min-max\":\n",
    "        data = np.array(weights).reshape(-1, 1)\n",
    "        scaler = MinMaxScaler_sklearn()\n",
    "        scaler.fit(data)\n",
    "        scaled_data = scaler.transform(data)\n",
    "        scaled_data = scaled_data.tolist()\n",
    "        scaled_data = [value[0] for value in scaled_data]\n",
    "\n",
    "    if normalized_weights:\n",
    "        normalized_weights = normalized_weights[0]\n",
    "        normalized_weights = [round(value, 3) for value in normalized_weights]\n",
    "    elif scaled_data:\n",
    "        normalized_weights = scaled_data\n",
    "\n",
    "    if sum_value:\n",
    "        print(\"sun weights: \", sum(normalized_weights))\n",
    "\n",
    "    if complete:\n",
    "        normalized_weights = dict(zip(factor_names, normalized_weights))\n",
    "    \n",
    "    return normalized_weights # , normalized_weights_dict\n",
    "\n",
    "def get_factor_weight_by_scores_normalized(scores: list):\n",
    "    sum_scores = sum(scores)\n",
    "    weights_final = []\n",
    "    for score in scores:\n",
    "        cal = round((score / sum_scores), 3)\n",
    "        weights_final.append(cal)\n",
    "    return weights_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sun weights:  1.0\n",
      "normalized_weights:  [0.152, 0.193, 0.166, 0.172, 0.172, 0.145]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# l1: L2 normalization, also known as L2 norm normalization or Euclidean normalization\\n\\nnormalized_weights = normalize_factor_weights(factor_weights=factor_weights, method_type=\"l2\", complete=False, sum_value=False)\\nnormalized_weights = get_factor_weight_by_scores_normalized(normalized_weights)\\nprint(\"normalized_weights: \", normalized_weights)\\nprint(\"sun: \", sum(normalized_weights))\\nprint()\\n\\n# max: Max Normalization (dividing by the highest value)\\n\\nnormalized_weights = normalize_factor_weights(factor_weights=factor_weights, method_type=\"max\", complete=False, sum_value=False)\\nnormalized_weights = get_factor_weight_by_scores_normalized(normalized_weights)\\nprint(\"normalized_weights: \", normalized_weights)\\nprint(\"sun: \", sum(normalized_weights))\\nprint()\\n\\n# min-max: Min-Max\\n\\nnormalized_weights = normalize_factor_weights(factor_weights=factor_weights, method_type=\"min-max\", complete=False, sum_value=False)\\nnormalized_weights = get_factor_weight_by_scores_normalized(normalized_weights)\\nprint(\"normalized_weights: \", normalized_weights)\\nprint(\"sun: \", sum(normalized_weights))\\n\\n'"
      ]
     },
     "execution_count": 2169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 normalization, also known as L1 norm normalization or Manhattan normalization\n",
    "\n",
    "normalized_weights = normalize_factor_weights(factor_weights=factor_weights, method_type=\"l1\", complete=False, sum_value=True)\n",
    "print(\"normalized_weights: \", normalized_weights)\n",
    "print()\n",
    "\n",
    "\"\"\"\n",
    "# l1: L2 normalization, also known as L2 norm normalization or Euclidean normalization\n",
    "\n",
    "normalized_weights = normalize_factor_weights(factor_weights=factor_weights, method_type=\"l2\", complete=False, sum_value=False)\n",
    "normalized_weights = get_factor_weight_by_scores_normalized(normalized_weights)\n",
    "print(\"normalized_weights: \", normalized_weights)\n",
    "print(\"sun: \", sum(normalized_weights))\n",
    "print()\n",
    "\n",
    "# max: Max Normalization (dividing by the highest value)\n",
    "\n",
    "normalized_weights = normalize_factor_weights(factor_weights=factor_weights, method_type=\"max\", complete=False, sum_value=False)\n",
    "normalized_weights = get_factor_weight_by_scores_normalized(normalized_weights)\n",
    "print(\"normalized_weights: \", normalized_weights)\n",
    "print(\"sun: \", sum(normalized_weights))\n",
    "print()\n",
    "\n",
    "# min-max: Min-Max\n",
    "\n",
    "normalized_weights = normalize_factor_weights(factor_weights=factor_weights, method_type=\"min-max\", complete=False, sum_value=False)\n",
    "normalized_weights = get_factor_weight_by_scores_normalized(normalized_weights)\n",
    "print(\"normalized_weights: \", normalized_weights)\n",
    "print(\"sun: \", sum(normalized_weights))\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Creation date</th>\n",
       "      <th>No. of Views</th>\n",
       "      <th>No. of Likes on YouTube</th>\n",
       "      <th>Rating on CourseMapper</th>\n",
       "      <th>No of. Save on CourseMapper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>highest count</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normalized score</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Similarity Score Creation date No. of Views  \\\n",
       "0     highest count               22            28           24   \n",
       "1  normalized score            0.152         0.193        0.166   \n",
       "\n",
       "  No. of Likes on YouTube Rating on CourseMapper No of. Save on CourseMapper  \n",
       "0                      25                     25                          21  \n",
       "1                   0.172                  0.172                       0.145  "
      ]
     },
     "execution_count": 2170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, key in enumerate(factor_weights):\n",
    "    col = [str(factor_weights[key])]\n",
    "    col.append(normalized_weights[i])\n",
    "    factor_weights[key] = col\n",
    "\n",
    "df = pd.DataFrame(factor_weights)\n",
    "new_column_data = [\"highest count\", \"normalized score\"]\n",
    "new_column_name = ''\n",
    "df.insert(0, new_column_name, new_column_data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
